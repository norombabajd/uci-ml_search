{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323aa29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SINGLEcore model with 10 topics\n",
      "build SUCCESSFUL, visualizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loren\\anaconda3\\envs\\vsearch\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "C:\\Users\\loren\\uci-ml_search\\lda_vis.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "C:\\Users\\loren\\uci-ml_search\\lda_vis.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>data, contains, class, dataset, file, set, geo...</td>\n",
       "      <td>[abalone, predicting, age, abalone, physical, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>data, contains, class, dataset, file, set, geo...</td>\n",
       "      <td>[adult, extraction, done, barry, becker, censu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>data, set, test, training, features, labels, h...</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>dataset, data, one, features, using, image, ti...</td>\n",
       "      <td>[anonymous, microsoft, web, data, created, dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>data, sensor, database, set, labels, values, p...</td>\n",
       "      <td>[arrhythmia, database, contains, attributes, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>483</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9181</td>\n",
       "      <td>data, set, one, used, information, attributes,...</td>\n",
       "      <td>[hepatitis, virus, hcv, egyptian, patients, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>data, gas, sensors, dataset, sensor, frequency...</td>\n",
       "      <td>[qsar, fish, toxicity, dataset, used, develop,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>485</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>data, gas, sensors, dataset, sensor, frequency...</td>\n",
       "      <td>[qsar, aquatic, toxicity, dataset, used, devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>486</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>data, sensor, database, set, labels, values, p...</td>\n",
       "      <td>[human, activity, recognition, continuous, amb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>487</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5406</td>\n",
       "      <td>data, gas, sensors, dataset, sensor, frequency...</td>\n",
       "      <td>[wisdm, smartphone, smartwatch, activity, biom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0              0               2              0.9836   \n",
       "1              1               2              0.9667   \n",
       "2              2               9              0.5500   \n",
       "3              3               0              0.7578   \n",
       "4              4               6              0.9861   \n",
       "..           ...             ...                 ...   \n",
       "483          483               3              0.9181   \n",
       "484          484               1              0.9893   \n",
       "485          485               1              0.9906   \n",
       "486          486               6              0.9988   \n",
       "487          487               1              0.5406   \n",
       "\n",
       "                                              Keywords  \\\n",
       "0    data, contains, class, dataset, file, set, geo...   \n",
       "1    data, contains, class, dataset, file, set, geo...   \n",
       "2    data, set, test, training, features, labels, h...   \n",
       "3    dataset, data, one, features, using, image, ti...   \n",
       "4    data, sensor, database, set, labels, values, p...   \n",
       "..                                                 ...   \n",
       "483  data, set, one, used, information, attributes,...   \n",
       "484  data, gas, sensors, dataset, sensor, frequency...   \n",
       "485  data, gas, sensors, dataset, sensor, frequency...   \n",
       "486  data, sensor, database, set, labels, values, p...   \n",
       "487  data, gas, sensors, dataset, sensor, frequency...   \n",
       "\n",
       "                                                  Text  \n",
       "0    [abalone, predicting, age, abalone, physical, ...  \n",
       "1    [adult, extraction, done, barry, becker, censu...  \n",
       "2                                                [nan]  \n",
       "3    [anonymous, microsoft, web, data, created, dat...  \n",
       "4    [arrhythmia, database, contains, attributes, l...  \n",
       "..                                                 ...  \n",
       "483  [hepatitis, virus, hcv, egyptian, patients, pr...  \n",
       "484  [qsar, fish, toxicity, dataset, used, develop,...  \n",
       "485  [qsar, aquatic, toxicity, dataset, used, devel...  \n",
       "486  [human, activity, recognition, continuous, amb...  \n",
       "487  [wisdm, smartphone, smartwatch, activity, biom...  \n",
       "\n",
       "[488 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import env, gensim, pyLDAvis\n",
    "import lda_prepare as lda\n",
    "import pyLDAvis.gensim_models as gensim_models\n",
    "import sys\n",
    "import lda_vis as ldav\n",
    "\n",
    "#cluster visualization\n",
    "'''\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "'''\n",
    "\n",
    "#Dominant Topics Visualization\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Latent Dirichlet Allocation model training using Gensim Multicore (10 topics)\n",
    "    corpus, id2word, data_words = lda.get_corpus(), lda.get_id2word(), lda.get_data_words()\n",
    "\n",
    "    #if len(sys.argv) != 3:\n",
    "    #    raise Exception(\"Usage: <#topics> <#cores>\")\n",
    "    try:\n",
    "        syscores = int(sys.argv[2])\n",
    "        systopics = int(sys.argv[1])\n",
    "    except:\n",
    "        syscores = 1\n",
    "        systopics = 10\n",
    "\n",
    "    if syscores > 1:\n",
    "        print(\"Using \" + str(syscores) + \" cores, training MULTIcore model with \" + str(systopics) + \" topics\")\n",
    "        lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=systopics, workers=syscores)\n",
    "    else:\n",
    "        print(\"Training SINGLEcore model with \" + str(systopics) + \" topics\")\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=systopics, update_every=0, passes=20)\n",
    "    \n",
    "    print('build SUCCESSFUL, visualizing...')\n",
    "    # Visualizations using pyLDAvis\n",
    "    \n",
    "    LDAvis_prepared = gensim_models.prepare(lda_model, corpus, id2word)\n",
    "    pyLDAvis.save_html(LDAvis_prepared, env.VISUALIZATION_PATH)\n",
    "    \n",
    "    topic_sents_keywords = ldav.format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_words)\n",
    "    dominant_topic = topic_sents_keywords.reset_index()\n",
    "    dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "    dominant_topic.head(10)\n",
    "    display(dominant_topic)\n",
    "    # Cluster Visualization\n",
    "    '''\n",
    "    topic_weights = []\n",
    "    for i, row_list in enumerate(lda_model[corpus]):\n",
    "        topic_weights.append([w for i, w in row_list[0]])\n",
    "    \n",
    "    arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "    arr = arr[np.amaz(arr, axis=1) > 0.35]\n",
    "\n",
    "    topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "    tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "    tsne_lda = tsne_model.fit_transform(arr)\n",
    "\n",
    "    output_notebook()\n",
    "    n_topics = 4\n",
    "    mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "    plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(systopics),\n",
    "                  plot_width=900, plot_height=700)\n",
    "    plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "    show(plot)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02d0de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
